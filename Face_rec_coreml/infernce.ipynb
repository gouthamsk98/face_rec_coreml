{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.4.1.post1 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.17.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coreMl infernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'YourModel.mlmodel' with the path to your model file\n",
    "model = ct.models.MLModel('./people.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classLabel': 'sahil', 'Identity': {'test': 0.0006146430969238281, 'sahil': 0.98095703125, 'gsk': 0.016937255859375, 'unknown': 0.0005054473876953125}}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img_path = 'gsk.jpeg'\n",
    "# Load and preprocess your image\n",
    "image = Image.open(img_path)\n",
    "image = image.resize((224, 224)) # Resize to match model's input size\n",
    "image.save('resized_image.jpg')\n",
    "predictions = model.predict({'input_1': image})\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HF infernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Rescale the image\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'dataset/train/dhanesh/snapshot_17.jpg'\n",
    "img_array = preprocess_image(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biboxdev/miniconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[[1.0000000e+00 4.9867386e-09 2.4844232e-10]]\n"
     ]
    }
   ],
   "source": [
    "# Load the modified model\n",
    "model_with_string_labels = tf.keras.models.load_model('people.h5')\n",
    "\n",
    "# Predict the class label for the single image\n",
    "predicted_label = model_with_string_labels.predict(img_array)\n",
    "\n",
    "# Print the predicted string label\n",
    "print(predicted_label)  # Since the output is in a batch format, we access the first element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image input, 'input_1' must be of type PIL.Image.Image in the input dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m coreml_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(coreml_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Get prediction from Core ML model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m coreml_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mcoreml_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreml_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compare predictions\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorFlow prediction:\u001b[39m\u001b[38;5;124m'\u001b[39m, tf_prediction)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/coremltools/models/model.py:627\u001b[0m, in \u001b[0;36mMLModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    624\u001b[0m MLModel\u001b[38;5;241m.\u001b[39m_check_predict_data(data)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__proxy__:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMLModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__proxy__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_and_convert_input_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _macos_version() \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m13\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/coremltools/models/model.py:669\u001b[0m, in \u001b[0;36mMLModel._get_predictions\u001b[0;34m(proxy, preprocess_method, data)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_predictions\u001b[39m(proxy, preprocess_method, data):\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[43mpreprocess_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/coremltools/models/model.py:615\u001b[0m, in \u001b[0;36mMLModel.predict.<locals>.verify_and_convert_input_dict\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_and_convert_input_dict\u001b[39m(d):\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify_input_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tensor_to_numpy(d)\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# TODO: remove the following call when this is fixed: rdar://92239209\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/coremltools/models/model.py:741\u001b[0m, in \u001b[0;36mMLModel._verify_input_dict\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_input_name_exists(input_dict)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# verify that the pillow image modes are correct, for image inputs\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify_pil_image_modes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/coremltools/models/model.py:752\u001b[0m, in \u001b[0;36mMLModel._verify_pil_image_modes\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_val, _PIL_IMAGE\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    751\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage input, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be of type PIL.Image.Image in the input dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(input_desc\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_desc\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mimageType\u001b[38;5;241m.\u001b[39mcolorSpace \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    754\u001b[0m     _proto\u001b[38;5;241m.\u001b[39mFeatureTypes_pb2\u001b[38;5;241m.\u001b[39mImageFeatureType\u001b[38;5;241m.\u001b[39mBGR,\n\u001b[1;32m    755\u001b[0m     _proto\u001b[38;5;241m.\u001b[39mFeatureTypes_pb2\u001b[38;5;241m.\u001b[39mImageFeatureType\u001b[38;5;241m.\u001b[39mRGB,\n\u001b[1;32m    756\u001b[0m ):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_val\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Image input, 'input_1' must be of type PIL.Image.Image in the input dict"
     ]
    }
   ],
   "source": [
    "# Load TensorFlow model and predict\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "img_size = 224\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('people.h5')\n",
    "\n",
    "# Preprocess the image for TensorFlow model\n",
    "img_path = 'dataset/test/dhanesh/snapshot_18.jpg'\n",
    "img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 255.0\n",
    "\n",
    "# Get prediction from TensorFlow model\n",
    "tf_prediction = model.predict(x)\n",
    "\n",
    "# Load Core ML model and predict\n",
    "import coremltools\n",
    "import PIL.Image\n",
    "\n",
    "coreml_model = coremltools.models.MLModel('people.mlmodel')\n",
    "\n",
    "# Preprocess the image for Core ML model (make sure preprocessing is the same)\n",
    "img = PIL.Image.open(img_path).resize((img_size, img_size))\n",
    "coreml_input = np.array(img).astype(np.float32) / 255.0\n",
    "coreml_input = np.expand_dims(coreml_input, axis=0)\n",
    "\n",
    "# Get prediction from Core ML model\n",
    "coreml_prediction = coreml_model.predict({'input_1': coreml_input})\n",
    "\n",
    "# Compare predictions\n",
    "print('TensorFlow prediction:', tf_prediction)\n",
    "print('Core ML prediction:', coreml_prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
